10-13-25 10:09 beginning initial setup work for A3. i have reorganized my CSC475 git repo to better keep track of files. I have copied over Matrix.class and Main.java because I want to re-use the same logic and engine made in A2. Going to research some on file i/o and efficient ways to read lots of data fast 
10-16-25 1:31pm officially beginning actual work on this. Working on a todo list for what all needs to be done
I will use the following recommended "meta parameters" and change them as needed to increase accuracy:
    eta = 3
    minibatch size m = 10 => 6000 inputs per minibatch
    30 epochs
I must now figure out the idea of what my matrices at each layer will look like. I must also research IO stuff to see what the best way to read in would be. I will likely use BufferedReader (and prob later BufferedWriter for saving weights and biases) as I have used it before in CSC325 for an assignment. The idea would then just be how do i delimit across the commas to only capture the values wanted and then i would need to convert those values back into their double representation instead of their character representation (which may present actual problems as i dont know of ASCII casting working to double)
10-16-25 1:49pm concensus I have reached is that I will assume the input layer is a 784x1 matrix. then the first weight matrix should be a 15 x 784 so that we get a 15 x 1 returned by that operation. this directly then implies that the bias layer should be a 15x1 for addition to be defined. then to get a 10x1 in final layer we should multiply this 15x1 by a 10x15 (other way around bc matrix mul not commutative) and add a 10x1 bias layer. I can now get started on reading in the file and filling matrices. After doing this, i think the next plan of action should be working through the batching process and understanding how this input is going to be processed with my preexisting logic from A2. Then filling weights and biases with random numbers. also i now see that i am misunderstanding that we will get doubles from the csv but rather we are going to get doubles by normalizing the values by dividing them all by 255
10-16-25 2:32pm implemented logic from old assignment that essentially just took each line of the file and turned it to a String and cast it to a char[]. problem with this is it will split digits that need to be together. so instead i need to find a way to literally just delimit about commas and then place values into returned matrix 
10-16-25 2:41pm changed it so that now it is splitting but the logic shared by both is actually reading the entire file. so i am now presented with two immediate solutions: return a Matrix[][] and read the entire file line by line and fill all of the inputs at one time, or change the method entirely to do something that will probably be more time consuming to think thru. i am going to go with the first route. the idea is that i will initialize a Matrix[][] of size [amount of minibatches][amount of inputs] (which i know ahead of time will be [10][6000]) and then iterate through the rows of this Matrix[] and then the columns and read the file line by line and split the numbers and fill matrices with each line, then that Matrix object will be placed at arr[i][j] and then so on and so forth
10-16-25 3:08pm logic is done for new readAndFill method. it now takes in a File object, an amount of inputs (columns in 2d array) and m which is the minibatch size. the idea is that once this is done, this is now our entire batch with minibatches inside. it compiles and the logic seems like it works despite taking a small bit to compile. had to debug an issue where i had the try block inside the inner for loop so i was literally just reopening the file over again and starting over. I was also iterating i instead of j in the j-for loop. i am now going to make a method to generate random weights and biases. the idea behind this will be i will pass in an m and an n value for the dimensions so that this can be used for both layers generation of weights and biases. 
10-17-25 6:17pm did some research and java has no built in way to randomly generate doubles in [-1, 1]. did some searching on range scaling and found a reference that i will cite above the method which is called genRandomMat(). it takes two dimensions, m and n, and fills a mxn matrix with doubles between [-1, 1] by scaling it backwards by 1 (which is -1)
10-17-25 9:04pm made new method that converts the labels of each line into one hot vectors. uses similar file reading logic, but takes the label as the first element in the .split() arr and I just cast that back to an int to get the index where a 1 should go in the matrix. it returns a Matrix[]. i think i have a good framework now to begin at least modifying my training engine. 
10-17-25 9:09pm i now realize that I am going to need to change some of my logic in how i am storing my batched data. I dont want a 2d matrix array because i am going to need to batch the data randomly later. gonna work on getting that logic fixed up 
10-17-25 9:14pm going to change my read file so that instead what it will do is just return an ArrayList of type Matrix
10-18-25 4:28pm realizing that i have misunderstood what m is. its the amount in each minibatch, not the amount of minibatches. that affects nothing yet other than the constant i defined
10-18-25 4:55pm ArrayList doesnt extend collections but Collections has a shuffle method that takes a List and ArrayList extends List. readAndFill() now returns a List<Matrix> so we can shuffle for the sake of SGD
10-18-25 5:09pm making a method to batch my data from the List<Matrix> after each epoch so that it can be rebatched every epoch to avoid a bunch of excess code in entry point. encountered an index out of bounds exception bc i was iterating across wrong index in readAndFill and was not hitting all of the inputs necessary 
10-18-25 11:58pm after doing some work and changing some stuff, i realize i dont quite understand how to actually properly "classify" images. going to do some research on common ways this is done if i can find any. it doesnt quite make sense to do it the way my original engine does it so there has to be some kind of way to train it using the label itself as the expected activation. essentially i am going to need to FURTHER associate them past just associated indexing
10-19-25 12:42am i think a similar approach to what i *kinda* did in the first part will work. put them input and associated label vector into an array and then add that array to a list that we can then shuffle each epoch. so the data is randomized without losing the label we want to compare it against so we arent just doing random comparisons. now going to see if i can get the training engine going to see if this actually classifies like i believe it will
10-19-25 9:52am changed batch to return List<List<Matrix[]>> and now i have a training engine going again after altering the logic to work around this further association of values. the training engine is not properly working as I want so today will be spent making it work and then if it is finished working on the other partws of the assignment. i am also iterating diagnostic statements over each minibatch which is not waht is intended for the assignment
10-19-25 1:07pm after taking a big break and looking back at it, i have now determined that the issue lied with a bug that i had in readAndFill() where it was grabbing the element at the j - 1 place, which is the label so I was including the label instead of the last actual wanted digit. my diagnostic statements have been fixed also. with eta = 3, 10 minibatches, 6000 per minibatch and 30 epochs, it gets around 70-77% accuracy. I am going to make some tweaks to what needs to be altered to get closer to 90-99%.  going to first try changing the amount of epochs to see if returns simply diminish with the other parameters. 
10-19-25 1:27pm noticing similar results even when changing epochs so im going to look back through all my methods and ensure that i am treating the data properly, particularly the new additions because they are the only ones interacting with values from files. 
10-19-25 1:31pm noticed that i was not properly normalizing values about 255 when processing inputs from strings to doubles so i modified that in readAndFill(). getting a bit better but not a ton with 40 epochs. gonna change batches/sizes and eta and try different configurations of that. with 40 epochs and eta = 3.5, got to 80-84%. it climbs much faster to around 65% before slowing down growth. considered switching to ReLU but that would require me to change my backprop formulas which i do not really want to do unless absolutely necessary. hit 88% with eta = 2 , minibatches = 20, m = 3000, and 50 epochs. 
10-19-25 3:06pm hit 90+% with 50 epochs, eta = 2.8, 60 minibatches and 1000 per minibatch. going to just let that be enough 
10-19-25 4:28pm moving training loop logic to a method of its own that takes epochs, minibatches, minibatch size, and learning rate and returns a List<Matrix[]> that will be used for potentially being saved to a file for later. i am also going to make an addition to this new method where the final 
10-20-25 12:23am did a lot of work without documenting. i started writing a lot of methods to perform the things being done in the main UI loop but they were becoming complicated and hard to track (mainly because i was overcomplicating them) so i scrapped them and just started brute forcing what each one did. i also was misunderstanding particularly what 3. wanted which is a full run through the data with current weights and biases and i was instead just holding the final network accuracy after it was trained. 4. logic is extremely similar to 3. besides what file and the size of it you are using. both of those cases are done alongside case 0 (quit) and case 1 (train the network). i need to implement a load and write method. for loading and writing, i will load and write to/from .csv's and let the first two numbers in the lines be the dimensions (rows and cols, respectively), and the other's will be the values stored at each position in the matrix. i will also implement the ascii art idea after doing some more research